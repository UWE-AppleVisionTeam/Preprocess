{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Iy5Ab1yh2okUroL_fk2yZp65MA_XzyJz","authorship_tag":"ABX9TyMbJVQ+QlpPu3cPRYicAYR6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R27r3ccUhGLf","executionInfo":{"status":"ok","timestamp":1730928115316,"user_tz":0,"elapsed":2034,"user":{"displayName":"yishan yang","userId":"14929369319669129017"}},"outputId":"8db2bc0f-1b36-4a89-e22c-7a6dd6f355d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["<_RepeatDataset element_spec=(TensorSpec(shape=(180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":9}],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import os\n","import pathlib\n","from google.colab import drive\n","\n","# 挂载 Google Drive\n","drive.mount('/content/drive')\n","\n","# 设置文件路径\n","counting_data_dir = '/content/drive/MyDrive/Machine Vision/Minne Apple Count/counting_data/counting/'\n","image_folder_counting_trains = counting_data_dir + 'train/images/'\n","image_folder_counting_test = counting_data_dir + '/test/images/'\n","image_folder_counting_val = counting_data_dir + 'val/images/'\n","\n","# 数据集参数\n","batch_size = 64\n","shuffle_size = 1000\n","img_height = 180\n","img_width = 180\n","\n","# 读取标签配对文件\n","# train\n","train_ground_truth = pd.read_csv(counting_data_dir + 'train/train_ground_truth.txt')\n","train_image_names = train_ground_truth['Image'].values\n","train_labels = train_ground_truth['count'].values\n","\n","# val\n","val_ground_truth = pd.read_csv(counting_data_dir + 'val/val_ground_truth.txt')\n","val_image_names = val_ground_truth['Image'].values\n","val_labels = val_ground_truth['count'].values\n","\n","# 构建完整路径(test没有配对文件)\n","train_image_paths = [os.path.join(image_folder_counting_trains, name) for name in train_image_names]\n","val_image_paths = [os.path.join(image_folder_counting_val, name) for name in val_image_names]\n","test_image_paths = [os.path.join(image_folder_counting_test, name) for name in os.listdir(image_folder_counting_test)]\n","\n","# 创建数据集\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels))\n","val_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_labels))\n","test_dataset = tf.data.Dataset.from_tensor_slices(test_image_paths)\n","\n","# 数据预处理\n","# 预处理函数\n","def preprocess(path, label=None):\n","    image = tf.io.read_file(path)\n","    image = tf.image.decode_jpeg(image, channels=3)  # 将图像解码为张量, decode_jpeg\n","    image = tf.image.resize(image, [img_height, img_width])  # 重新设置尺寸\n","    image = image / 255.0  #归一化\n","    return image, label\n","\n","train_dataset = train_dataset.map(preprocess)\n","val_dataset = val_dataset.map(preprocess)\n","test_dataset = test_dataset.map(preprocess)\n","\n","# 设置每批64个\n","train_dataset.batch(batch_size)\n","val_dataset.batch(batch_size)\n","test_dataset.batch(batch_size)\n","\n","# 打乱数据\n","train_dataset.shuffle(shuffle_size)\n","val_dataset.shuffle(shuffle_size)\n","test_dataset.shuffle(shuffle_size)\n","\n","# 设置迭代次数\n","train_dataset.repeat(2)\n"]}]}