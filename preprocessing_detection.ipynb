{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Iy5Ab1yh2okUroL_fk2yZp65MA_XzyJz","authorship_tag":"ABX9TyNw4/Jz0tbE9Ab2DWnvBdCU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R27r3ccUhGLf","executionInfo":{"status":"ok","timestamp":1730930082926,"user_tz":0,"elapsed":1800,"user":{"displayName":"yishan yang","userId":"14929369319669129017"}},"outputId":"8986a128-2d47-4ef7-d1e8-52279e82c088"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["<_RepeatDataset element_spec=(TensorSpec(shape=(180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(180, 180, 1), dtype=tf.float32, name=None))>"]},"metadata":{},"execution_count":2}],"source":["import tensorflow as tf\n","import numpy as np\n","import cv2\n","import os\n","from google.colab import drive\n","\n","# 挂载 Google Drive\n","drive.mount('/content/drive')\n","\n","# 设置文件路径\n","detection_data_dir = '/content/drive/MyDrive/Machine Vision/Minne Apple Count/detection/'\n","image_folder_detection_trains = detection_data_dir + 'train/images/'\n","image_folder_detection_masks = detection_data_dir + 'train/masks/'\n","image_folder_detection_test = detection_data_dir + 'test/images/'\n","\n","# 数据集参数\n","batch_size = 64\n","shuffle_size = 1000\n","img_height = 180\n","img_width = 180\n","\n","# 获取训练文件和掩码文件\n","train_image_names = os.listdir(image_folder_detection_trains)\n","mask_image_names = os.listdir(image_folder_detection_masks)\n","test_image_names = os.listdir(image_folder_detection_test)\n","\n","# 构建完整路径\n","train_image_paths = [os.path.join(image_folder_detection_trains, name) for name in train_image_names]\n","mask_image_paths = [os.path.join(image_folder_detection_masks, name) for name in mask_image_names]\n","test_image_paths = [os.path.join(image_folder_detection_test, name) for name in test_image_names]\n","\n","# 将数据集拆分，划分训练集和验证集，80%训练，20%验证\n","train_size = int(0.8 * len(train_image_paths))\n","val_size = len(train_image_paths) - train_size\n","train_image_paths, val_image_paths = train_image_paths[:train_size], train_image_paths[train_size:]\n","train_mask_paths, val_mask_paths = mask_image_paths[:train_size], mask_image_paths[train_size:]\n","\n","# 创建数据集\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_mask_paths))\n","val_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_mask_paths))\n","test_dataset = tf.data.Dataset.from_tensor_slices(test_image_paths)\n","\n","# 边界框生成函数\n","def mask_to_bboxes(mask):\n","    # 将掩码转换为 NumPy 数组，然后转为二值图片（苹果转白色）\n","    mask_np = mask.numpy().astype(np.uint8)\n","    _, binary_mask = cv2.threshold(mask_np, 1, 255, cv2.THRESH_BINARY)\n","    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    bboxes = []\n","\n","    for contour in contours:\n","        x, y, w, h = cv2.boundingRect(contour)  # 获取外接矩形\n","        bboxes.append([x, y, x+w, y+h])  # [x_min, y_min, x_max, y_max]\n","\n","    return bboxes\n","\n","# 数据预处理，读取文件，解码，重新设置尺寸，归一化\n","# 预处理函数\n","def preprocess(image_path, mask_path=None):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, [img_height, img_width])\n","    image = image / 255.0\n","\n","    if mask_path is not None:\n","        mask = tf.io.read_file(mask_path)\n","        mask = tf.image.decode_png(mask, channels=1) #掩码单通道\n","        mask = tf.image.resize(mask, [img_height, img_width])\n","        mask = mask / 255.0\n","        bboxes = mask_to_bboxes(mask)\n","        return image, bboxes\n","    else:\n","        return image\n","\n","train_dataset = train_dataset.map(preprocess)\n","val_dataset = val_dataset.map(preprocess)\n","test_dataset = test_dataset.map(preprocess)\n","\n","# 设置每批64个\n","train_dataset.batch(batch_size)\n","val_dataset.batch(batch_size)\n","test_dataset.batch(batch_size)\n","\n","# 打乱数据\n","train_dataset.shuffle(shuffle_size)\n","val_dataset.shuffle(shuffle_size)\n","test_dataset.shuffle(shuffle_size)\n","\n","# 预取数据来提高性能\n","train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","# 设置迭代次数\n","train_dataset.repeat(2)\n"]}]}
